[["index.html", "My portfolio Chapter 1 Introduction", " My portfolio Claudia van der Zijden 2021-06-17 Chapter 1 Introduction Welkom to my portfolio! In my portfolio I try to give an impression of my programming skills. This is mainly in r but I also have some experience with bash. This portfolio contains a number of chapters with assignments that I have made, it also contains my resume. The last chapter called machine learning is about a tutorial assignment in which I tried to learn more about machine learning. I hope this portfolio will give you a good idea of my skills. For further questions you can always email claudiavanderzijden@hotmail.nl "],["reproducible-research.html", "Chapter 2 Reproducible research", " Chapter 2 Reproducible research C. elegans plate experiment The data for this exercise was kindly supplied by J. Louter (INT/ILC) and was derived from an experiment in which adult C.elegans nematodes were exposed to varying concentrations of different compounds. The variables RawData (the outcome - number of offspring counted as an integer value, after incubation time), compName (the generic name of the compound/chemical), the compConcentration (the concentration of the compound), and the expType are the most important variables in this dataset. A typical analysis with this data would be to run a dose-response analysis using a log-logistic model with estimates for the maximal, the minimal, the IC50 concentration and the slope at IC50. We will not go into the details but a good package to run such computations and create graphs in R is the {drc} package. See: and:. In the exercise below we will create some visualizations using {ggplot2}. Before we start, we will inspect the dataset. We do this by opening it in Excel. When you look at this dataset, a few things stand out. Among other things, there are many tabs with very large tables without an explanation. This makes it difficult for outsiders to use this data. Then we will load the data into rstudio. library(tidyverse) ## -- Attaching packages --------------------------------------- tidyverse 1.3.1 -- ## v ggplot2 3.3.3 v purrr 0.3.4 ## v tibble 3.1.2 v dplyr 1.0.6 ## v tidyr 1.1.3 v stringr 1.4.0 ## v readr 1.4.0 v forcats 0.5.1 ## -- Conflicts ------------------------------------------ tidyverse_conflicts() -- ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(readxl) ce_liq_flow_062 &lt;- read_excel(&quot;data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;, sheet = 1) Now we can look at the data types. we will do this for the columns rawData, compName and compConcentration. typeof(ce_liq_flow_062$RawData) ## [1] &quot;double&quot; typeof(ce_liq_flow_062$compName) ## [1] &quot;character&quot; typeof(ce_liq_flow_062$compConcentration) ## [1] &quot;character&quot; You would expect comConcentration to be numeric but as you can see this is character. Now we are going to make a scatter plot of the data. We put compconcentration on the x-axis and DataRaw on the y-axis. We give a different color to the levels of compname and a different shape to the levels of expType. In addition, we ensure that the numbers below the x-axis are rotated 45 degrees so that we can read those. ggplot(data = ce_liq_flow_062, aes(x = compConcentration, y = RawData)) + geom_point(aes(colour = compName, shape = expType)) + scale_x_discrete(guide = guide_axis(angle = 45)) + labs(title = &quot;compConcentration is double&quot;) ## Warning: Removed 5 rows containing missing values (geom_point). If we now look at this plot, you can see that the scale of the x-axis is not linearly distributed. This is probably due to the data type of comcondition. So were going to change it to numeric. Then we will plot the data again. We now use a log10 transformation to improve the distribution of the x-axis. We also use jitter to avoid overlapping data points. ce_liq_flow_062$compConcentration &lt;- as.numeric(as.character(ce_liq_flow_062$compConcentration)) ## Warning: NAs introduced by coercion typeof(ce_liq_flow_062$compConcentration) ## [1] &quot;double&quot; log10_scatter &lt;-ggplot(data = ce_liq_flow_062, aes(x = compConcentration, y = RawData)) + geom_point(position=position_jitter(width=.1,height=0),aes(colour = compName, shape = compName)) + scale_x_discrete(guide = guide_axis(angle = 45))+ labs(title = &quot;compConcentration is numeric&quot;) log10_scatter + scale_x_log10() ## Scale for &#39;x&#39; is already present. Adding another scale for &#39;x&#39;, which will ## replace the existing scale. ## Warning: Transformation introduced infinite values in continuous x-axis ## Warning: Removed 6 rows containing missing values (geom_point). The positive control for this experiments is naphthale. The negative control for this experiment is S-medium. After reviewing the data, we could proceed with the analysis of the data to find out whether there is indeed an effect of different concentrations on offspring count and whether the different compounds have a different curve. To find out, first check whether the data is normally distributed. This can be done with the shapio-wilk test. This can be used to determine whether a parametric or non-parametric test can be used to see if there is a statistically significant difference between the different groups. Finaly we normalize the data for the controlNegative in such a way that the mean value for controlNegative is exactly equal to 1 and all other values are expressed as a fraction thereof. Than we rerun the graph with the normalized data. ``{r 1.1J} normalize &lt;- function(x) { return ((x - min(x)) / (max(x) - min(x))) } ce_liq_flow_062\\(compVehicle %&gt;% normalize(filter(ce_liq_flow_062\\)compVehicle == controlNegative)) H.Why would you want to take the step under J? &lt;!--chapter:end:02-Reproducible_Research.Rmd--&gt; #Open Peer Review This exercise is about identifying reproducibility issues in a scientific publication. We use the criteria for reproduciblity that are publically available via here Transparency Criteria Definition Response Type Study Purpose A concise statement in the introduction of the article, often in the last paragraph, that establishes the reason the research was conducted. Also called the study objective. Binary Data Availability Statement A statement, in an individual section offset from the main body of text, that explains how or if one can access a studys data. The title of the section may vary, but it must explicitly mention data; it is therefore distinct from a supplementary materials section. Binary Data Location Where the articles data can be accessed, either raw or processed. Found Value Study Location Author has stated in the methods section where the study took place or the datas country/region of origin. Binary; Found Value Author Review The professionalism of the contact information that the author has provided in the manuscript. Found Value Ethics Statement A statement within the manuscript indicating any ethical concerns, including the presence of sensitive data. Binary Funding Statement A statement within the manuscript indicating whether or not the authors received funding for their research. Binary Code Availability Authors have shared access to the most updated code that they used in their study, including code used for analysis. Binary Table clarification The Transparency Criteria are criteria you need to score the article of your choice for. Read them carefully and discuss with another course participant if you do not understand them. Each Tranparance criterion comes with a Definition that explains the criterion in more details. These descriptions are particularly helpful to understand what the criterium entails and what to look for in the article. The Response Type is the actual score In this assisgment you need to find a scientific article yourself, using PubMed or another database or repository. Use only Open Access articles. Having an article in hand, go over the table above and score the article according the criteria. Be sure to select a primary article that presents a study using data from experimental work . This can be laboratory experiments or in silico experiments. Reviews and meta analysis are not suitable for this assignment To guide your search you can choose between these topics Coronavirus / COVID-19 The effects of compound on an organism / Toxicology The effectiveness of a drug or treatment in an animal study The effects of a compound investigated in a cell or organoid system https://www.biorxiv.org/content/10.1101/2020.10.02.322917v2.full Study Purpose : er wordt in de samenvatting kort uitgelegd wat voor belanger er is om dit onderzoek uit te voeren Data Availability Statement: niet aanwezig Data Location: er wordt wel bescreven hoe de data er uit moet zien en er zijn verwijzingen naar waar artikelen waar in wordt beschrevenhoe de data verzameld is. Er staat niet waar je de gebruikte data terug kan vinden. Study Location: in de materiaal en methode sectie staat geen informatie over waar het onderzoek is uitgevoerd Author Review: de gegevens van de auteurs zijn niet makkelij te verkrijgen, de namen van de auteurs staan boven aan het artkel maar verdere contact gegevens staan niet op de pagina zelf. Ethics Statement: in de introductie staat kort iets over de ethiek Funding Statement: er wordt niets gezegt over de financiering Code Availability: er wordt geen code gedeeld in het artikel TIPS If you do not know where to start your literature search start here: https://www.biorxiv.org/ This assignment is not about the topic you select, so try to do that quickly You may want to cheat and select an article that scores TRUE on the Data Availability Statement, because that enables you to use the this article again in one of the next assignments. PART 1 To complete part 1, execute activity A to G Initiate an empty RMarkdown file in your RStudio environment and provide author and title (after the title of this exercise) Search for a primary Open Access article on one of the above listed topics, using Pubmed Central Read the article diagonally to check if is indeed a primary article describing emperical scientific findings. Include the reference to this article in your Rmd file Score the article on the basis of the above Repita criteria Write an Rmarkdown report on your findings, including the table above and some information about the article such as general aim, short methods and results. If data is available, try including some # Open peer review Store the source Rmd and knitted HTML in a folder called Rmd in your course RStudio project. You will need it again later in the course PART 2 To complete this assignment you will have to execute activity H to P Using the OSF website, select a project that addresses an aspect of the SARS-Cov-2 virus. Select a project that has a dataset and R-code shared in the project environment. Have a look at the code. Describe in your own words what the code intents to achieve. In terms of readibility of the code, how would you grade (1(very bad)-5(very good)) the code available. Download the code and the data to a new RStudio project Run the script or code that is available to reproduce at least 1 figure When you encounter errors or flaws in the script, try fixing them and record your changes. Taken together on a scale from 1 (very hard) to 5 (very easy), how much effort did it take you to reproduce the visualization from the project, report or article Generate an RMarkdown script that contains the details on the project you selected, the code you used to create the visualization and your score for reproducibility. resource: https://www.researchgate.net/publication/340244621_Reproducibility_and_reporting_practices_in_COVID-19_preprint_manuscripts/fulltext/5e81f9fd92851caef4ae37ba/Reproducibility-and-reporting-practices-in-COVID-19-preprint-manuscripts.pdf ```r #https://osf.io/gkcn7/ library(readxl) #salmonellacfu &lt;- read_excel(&quot;salmonella&quot;) "],["guerrilla-analytics.html", "Chapter 3 Guerrilla analytics", " Chapter 3 Guerrilla analytics "],["curriculum-vitae.html", "Chapter 4 Curriculum vitae", " Chapter 4 Curriculum vitae We have finished a nice book. "],["mendaly.html", "Chapter 5 Mendaly", " Chapter 5 Mendaly "],["looking-ahead.html", "Chapter 6 Looking ahead", " Chapter 6 Looking ahead "],["relational-databases.html", "Chapter 7 Relational databases", " Chapter 7 Relational databases TIPS Be aware, the flu and dengue data contains metadata that should be stripped from the data on load. Think of a way to create valid country names that fit with the gapminder data. Remember (!) that in the end, this assignment needs to be reported by a .Rmd file for your portfolio. So save what you are doing, save your SQL scripts, make screenshots if you want, and in general design a clear and attractive report in RMarkdown to showcase your SQL/database-skills in your portfolio. You may be sending this to propspective employers in the future! (also, the portfolio is what we as teachers will be grading. But definitely think about the future rather than only about passing the course) Assignment Load the flu (./data/flu_data.csv), the dengue (./data/dengue_data.csv) and the gapminder ({dslabs} package) into three separate dataframes in R Check if they are in the right shape. Is the data in the tidy format? If not change the format to tidy Change the country and date variables of the three tables so that they coincide in terms of data type, class and values Store the three tables as separate (so six in total) .csv and .rds files. In Dbeaver create a new PostgreSQL database workflowsdb Using RPostgreSQL, insert the tables into the database. Inspect the contents of the tables with SQL (in DBeaver) and save the SQL script. Inspect the contents of the tables with dplyr (in R) and save a RMarkdown showing what you are doing. Load the gapminder data in R and change the dataframe in such as way that you could join it to dengue and flue. Save this clean gapminder data in the workflowsdb database Perform some joins (your choice) with SQL (can be done in DBeaver or with dplyr. Generate a joined table, and export this from the database to R. Show some descriptive statistics with this table, and at least 3 visualisations using ggplot2. show all of your actions in this assignment in a Rmd file, perhaps with pictures and provide text explaining and showcasing your skills. library(tidyverse) library(dslabs) gapminder &lt;- as_tibble(gapminder) flu_data&lt;- read.csv(url(&quot;https://raw.githubusercontent.com/ClaudiavdZ/tlsc-dsfb26v-20_workflows/main/data/flu_data.csv&quot;), skip = 11) flu_data &lt;- as_tibble(flu_data) dengue_data&lt;- read.csv(url(&quot;https://raw.githubusercontent.com/ClaudiavdZ/tlsc-dsfb26v-20_workflows/main/data/dengue_data.csv&quot;), skip = 11) write.table(dengue_data , file = &quot;dengu_data.csv&quot;) write.table(dengue_data , file = &quot;dengu_data.RDS&quot;) write.table(flu_data , file = &quot;flu_data.csv&quot;) write.table(flu_data , file = &quot;flu_data.RDS&quot;) write.table(gapminder , file = &quot;gapminder.csv&quot;) write.table(gapminder , file = &quot;gapminder.RDS&quot;) library(DBI) con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;myfirstdb&quot;, host=&quot;localhost&quot;, port=&quot;5432&quot;, user=&quot;postgres&quot;, password=&quot;Veroni36&quot;) dbListTables(con) ## [1] &quot;test&quot; &quot;gapminder&quot; &quot;flu_data&quot; &quot;dengue_data&quot; #dbWriteTable(con, &quot;dengue_data&quot;, dengue_data) #dbWriteTable(con, &quot;flu_data&quot;, flu_data) #dbWriteTable(con, &quot;gapminder&quot;, gapminder) # library(janitor) # gapminder_usd &lt;- as.data.frame(t(gapminder)) # gapminder_usd &lt;- gapminder_usd %&gt;% row_to_names(row_number = 1) flu_usd &lt;- gather( flu_data, key = &quot;country&quot;, value = &quot;flu&quot;, Argentina:Uruguay ) #seperate year from month and day flu_usd &lt;- separate(flu_usd, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) #count sum of flu flu_usd &lt;- aggregate(flu_usd$flu, by=list(year=flu_usd$year, country=flu_usd$country), FUN=sum) flu_usd &lt;- flu_usd %&gt;% rename(flu = x) flu_usd$year &lt;- as.integer(flu_usd$year) dengue_usd &lt;- gather( dengue_data, key = &quot;country&quot;, value = &quot;dengue&quot;, Argentina:Venezuela ) dengue_usd &lt;- separate(dengue_usd, Date, into = c(&quot;year&quot;, &quot;month&quot;, &quot;day&quot;), sep = &quot;-&quot;) dengue_usd &lt;- aggregate(dengue_usd$dengue, by=list(year=dengue_usd$year, country=dengue_usd$country), FUN=sum) dengue_usd &lt;- dengue_usd %&gt;% rename(dengue = x) dengue_usd$year &lt;- as.integer(dengue_usd$year) alltogether &lt;- left_join(flu_usd, gapminder, by = c(&quot;country&quot;, &quot;year&quot;)) alltogether &lt;- left_join(alltogether, dengue_usd , by = c(&quot;country&quot;, &quot;year&quot;)) #infant_mortelity firtelety life expantie door flu and dengue in verschillende jaren in verschillende landen #en beetje statestiek "],["my-own-package.html", "Chapter 8 My own package", " Chapter 8 My own package "],["machine-learning.html", "Chapter 9 Machine learning", " Chapter 9 Machine learning "],["appendix.html", "Chapter 10 Appendix", " Chapter 10 Appendix "]]
